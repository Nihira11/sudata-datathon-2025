---
title: "Modelling"
author: "Nihira"
date: "2025-10-01"
output: html_document
---

```{r}
library(tidyverse)
library(lubridate)
library(janitor)
library(caret)
library(randomForest)
library(xgboost)
library(nnet)
library(vip)
library(pROC)
library(dplyr)
library(tibble)
library(knitr)
library(kableExtra)
library(MASS)
library(car)

set.seed(123)
```

```{r}
df <- read_csv("~/Desktop/sudata-datathon-2025/datasets/dynamic_supply_chain_logistics_dataset.csv") %>%
  clean_names()

glimpse(df)
```

```{r}
# Risk Classification
df$risk_classification <- df$risk_classification %>%
  tolower() %>%
  trimws() %>%
  factor(levels = c("low risk", "moderate risk", "high risk"),
         labels = c("low_risk", "moderate_risk", "high_risk"))

# Delivery time deviation
df$delivery_time_deviation <- as.numeric(df$delivery_time_deviation)

# Delay probability
df$delay_probability <- as.numeric(df$delay_probability)
df$delay_probability[df$delay_probability < 0] <- 0
df$delay_probability[df$delay_probability > 1] <- 1
```

```{r}
drop_cols <- c("timestamp","vehicle_gps_latitude","vehicle_gps_longitude")

targets <- c(
  "disruption_likelihood_score",
  "delay_probability",
  "risk_classification",
  "delivery_time_deviation"
)

drop_leakage <- function(data, target) {
  other_targets <- setdiff(targets, target)
  data %>% dplyr::select(-all_of(c(drop_cols, other_targets)))
}

features <- setdiff(names(df), drop_cols)
```

```{r}
# Risk Classification
cls <- df %>% drop_na(risk_classification)
idx_cls <- createDataPartition(cls$risk_classification, p = 0.8, list = FALSE)
train_cls <- cls[idx_cls,]; test_cls <- cls[-idx_cls,]

# Delivery Deviation
reg <- df %>% drop_na(delivery_time_deviation)
idx_reg <- createDataPartition(reg$delivery_time_deviation, p = 0.8, list = FALSE)
train_reg <- reg[idx_reg,]; test_reg <- reg[-idx_reg,]

# Delay Probability
dly <- df %>% drop_na(delay_probability) %>%
  mutate(delayed = factor(if_else(delay_probability >= 0.5, "yes", "no"), 
                          levels = c("no","yes")))
idx_dly <- createDataPartition(dly$delay_probability, p = 0.8, list = FALSE)
train_dly <- dly[idx_dly,]; test_dly <- dly[-idx_dly,]

# Disruption Likelihood
disr <- df %>% drop_na(disruption_likelihood_score)
idx_disr <- createDataPartition(disr$disruption_likelihood_score, p = 0.8, list = FALSE)
train_disr <- disr[idx_disr,]; test_disr <- disr[-idx_disr,]
```

```{r}
# Risk Classification
train_cls_noleak <- drop_leakage(train_cls, "risk_classification")
test_cls_noleak  <- drop_leakage(test_cls,  "risk_classification")

# Multinomial Logistic
model_multinom <- train(
  risk_classification ~ .,
  data = train_cls_noleak,
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, sampling = "smote"),
  preProcess = c("center","scale"),
  trace = FALSE
)
pred_multinom <- predict(model_multinom, test_cls_noleak)
confusionMatrix(pred_multinom, test_cls$risk_classification)
```

```{r}
# XGBoost
grid <- expand.grid(
  nrounds = 100,
  max_depth = c(3, 5),
  eta = 0.1,
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
)

ctrl <- trainControl(
  method = "cv",
  number = 3,
  sampling = "smote"
)

model_xgb <- train(
  risk_classification ~ .,
  data = train_cls_noleak,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = grid
)
pred_xgb <- predict(model_xgb, newdata = test_cls_noleak)
pred_xgb <- factor(pred_xgb, levels = levels(test_cls$risk_classification))
confusionMatrix(pred_xgb, test_cls$risk_classification)
```

```{r}
vip(model_xgb$finalModel, num_features = 15) +
  ggtitle("XGB: Risk Classification\nFeature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen") +
  theme(legend.position = "none")
```

```{r}
# Delivery Time Deviation
train_reg_noleak <- drop_leakage(train_reg, "delivery_time_deviation")
test_reg_noleak  <- drop_leakage(test_reg,  "delivery_time_deviation")

# Linear Regression
model_lm <- train(
  delivery_time_deviation ~ .,
  data = train_reg_noleak,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center","scale")
)
pred_lm <- predict(model_lm, newdata = test_reg_noleak)
met_lm  <- postResample(pred_lm, test_reg$delivery_time_deviation)
```

```{r}
vip(model_lm$finalModel, num_features = 15) +
  ggtitle("Linear Regression: Delivery Deviation\nFeature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradientn(colors = c("yellow", "orange", "red", "purple", "blue")) +
  theme(legend.position = "none")

```

```{r}
# XGBoost Regression
grid <- expand.grid(
  nrounds = 100,
  max_depth = c(3, 5),
  eta = 0.1,
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
)

model_xgb_reg <- train(
  delivery_time_deviation ~ .,
  data = train_reg_noleak,
  method = "xgbTree",
  trControl = trainControl(method = "cv", number = 3),
  tuneGrid = grid
)
pred_xgb_reg <- predict(model_xgb_reg, newdata = test_reg_noleak)
met_xgb_reg  <- postResample(pred_xgb_reg, test_reg$delivery_time_deviation)
print(met_xgb_reg)
```

```{r}
vip(model_lm$finalModel, num_features = 15) +
  ggtitle("Linear Regression: Delivery Deviation\nFeature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradientn(colors = c("pink", "violet", "purple", "darkblue")) +
  theme(legend.position = "none")
```

```{r}
# Delay Probability

# Data Prep
train_dly_noleak <- drop_leakage(train_dly, "delay_probability")
test_dly_noleak  <- drop_leakage(test_dly,  "delay_probability")

train_dly_cls <- train_dly_noleak %>%
  mutate(delayed = factor(if_else(delay_probability >= 0.5, "yes","no"), levels=c("no","yes")))
test_dly_cls  <- test_dly_noleak %>%
  mutate(delayed = factor(if_else(delay_probability >= 0.5, "yes","no"), levels=c("no","yes")))

feat_cols <- setdiff(names(train_dly_cls), c("delayed","delay_probability")) 

table(train_dly_cls$delayed)
prop.table(table(train_dly_cls$delayed))
```

```{r}
# Logistic Regression (baseline)
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  sampling = "smote"
)
model_logit <- train(
  x = train_dly_cls[, feat_cols] %>% as.data.frame(),
  y = train_dly_cls$delayed,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "ROC"
)

pred_logit <- predict(model_logit, test_dly_cls[, feat_cols])
confusionMatrix(pred_logit, test_dly_cls$delayed, positive = "yes")
```

```{r}
vip(model_logit$finalModel, num_features = 15) +
  ggtitle("Logistic Regression: Delay Probability\nFeature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradient(low = "orange", high = "red") +
  theme(legend.position = "none")
```

```{r}
# Data Prep 2
train_dly_cls <- train_dly %>%
  mutate(delayed = factor(if_else(delay_probability >= 0.5, "yes", "no"),
                          levels = c("no","yes")))
test_dly_cls <- test_dly %>%
  mutate(delayed = factor(if_else(delay_probability >= 0.5, "yes", "no"),
                          levels = c("no","yes")))

targets <- c("disruption_likelihood_score",
             "delay_probability",
             "risk_classification",
             "delivery_time_deviation")

feat_cols <- setdiff(colnames(train_dly_cls),
                     c("delayed", targets, drop_cols))

train_mat <- train_dly_cls[, feat_cols, drop = FALSE] %>%
  dplyr::mutate(dplyr::across(where(is.logical), as.integer))
test_mat  <- test_dly_cls[, feat_cols, drop = FALSE] %>%
  dplyr::mutate(dplyr::across(where(is.logical), as.integer))

dmy <- caret::dummyVars(~ ., data = train_mat, fullRank = TRUE)
X_train <- as.data.frame(predict(dmy, newdata = train_mat))
X_test  <- as.data.frame(predict(dmy, newdata = test_mat))

nzv <- caret::nearZeroVar(X_train)
if (length(nzv)) X_train <- X_train[, -nzv, drop = FALSE]
X_test <- X_test[, colnames(X_train), drop = FALSE]

train_xgb <- cbind(delayed = train_dly_cls$delayed, X_train)
test_xgb  <- cbind(delayed = test_dly_cls$delayed,  X_test)
```

```{r}
# XGBoost
ctrl <- trainControl(
  method = "cv", number = 3,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  sampling = "down"
)

grid <- expand.grid(
  nrounds = 50,
  max_depth = c(3, 5),
  eta = 0.1,
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
)

model_xgb <- train(
  delayed ~ .,
  data = train_xgb,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = grid,
  metric = "ROC",
)

pred_xgb <- predict(model_xgb, newdata = test_xgb)
confusionMatrix(pred_xgb, test_xgb$delayed, positive = "yes")
```

```{r}
vip(model_xgb$finalModel, num_features = 15) +
  ggtitle("XGB: Delay Probability â€” Feature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradientn(colors = c("orange", "magenta", "red")) +
  theme(legend.position = "none")
```

```{r}
# Disruption Likelihood Score
train_disr_noleak <- drop_leakage(train_disr, "disruption_likelihood_score")
test_disr_noleak  <- drop_leakage(test_disr,  "disruption_likelihood_score")

# Linear Regression
model_lm_disr <- train(
  disruption_likelihood_score ~ .,
  data = train_disr_noleak,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale")
)

pred_lm_disr <- predict(model_lm_disr, newdata = test_disr_noleak)
met_lm_disr  <- postResample(pred_lm_disr, test_disr$disruption_likelihood_score)
print(met_lm_disr)
```

```{r}
vip(model_lm_disr$finalModel, num_features = 15) +
  ggtitle("Linear Regression: Disruption Likelihood\nFeature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen") +
  theme(legend.position = "none")
```

```{r}
# XGBoost
grid_disr <- expand.grid(
  nrounds = 100,
  max_depth = c(3, 5),
  eta = 0.1,
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
)

model_xgb_disr <- train(
  disruption_likelihood_score ~ .,
  data = train_disr_noleak,
  method = "xgbTree",
  trControl = trainControl(method = "cv", number = 3),
  tuneGrid = grid_disr
)

pred_xgb_disr <- predict(model_xgb_disr, newdata = test_disr_noleak)
met_xgb_disr  <- postResample(pred_xgb_disr, test_disr$disruption_likelihood_score)
print(met_xgb_disr)
```

```{r}
vip(model_xgb_disr$finalModel, num_features = 15) +
  ggtitle("XGB: Disruption Likelihood\nFeature Importance") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size = 16, lineheight = 1.1)) +
  geom_bar(stat = "identity", aes(fill = Importance)) +
  scale_fill_gradientn(colors = c("gold", "orange", "brown")) +
  theme(legend.position = "none")
```


## Model Selection

```{r}
# Build formula for full model (exclude leakage cols and other targets)
form_cls <- as.formula(
  paste("risk_classification ~",
        paste(setdiff(names(train_cls_noleak), "risk_classification"),
              collapse = "+"))
)

# Full multinomial model
full_model_cls <- multinom(form_cls, data = train_cls_noleak, trace = FALSE)

# Null model (intercept only)
null_model_cls <- multinom(risk_classification ~ 1, data = train_cls_noleak, trace = FALSE)

# ---- Stepwise with AIC (both directions) ----
step_aic_cls <- stepAIC(
  null_model_cls,
  scope = list(lower = null_model_cls, upper = full_model_cls),
  direction = "both",
  trace = TRUE
)
summary(step_aic_cls)

# ---- Stepwise with BIC (both directions) ----
n_cls <- nrow(train_cls_noleak)
step_bic_cls <- stepAIC(
  null_model_cls,
  scope = list(lower = null_model_cls, upper = full_model_cls),
  direction = "both",
  k = log(n_cls),   # BIC penalty
  trace = TRUE
)
summary(step_bic_cls)
```

```{r}
pred_aic <- predict(step_aic_cls, newdata = test_cls_noleak)
confusionMatrix(pred_aic, test_cls$risk_classification)
```

```{r}
pred_bic <- predict(step_bic_cls, newdata = test_cls_noleak)
confusionMatrix(pred_bic, test_cls$risk_classification)
```

